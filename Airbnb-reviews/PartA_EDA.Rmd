---
title: "PartA"
author: "Yibo"
date: "3/18/2020"
output:
  word_document: default
  html_document: default
editor_options:
  chunk_output_type: inline
---
```{r}
knitr::opts_chunk$set(eval = FALSE)
```

```{r}
# ----- Connect to the database
library(tidyverse)
library(dplyr)
library(RSQLite)
con <- dbConnect(RSQLite::SQLite(), "/Users/zhaoyibo/Desktop/TAfinal/inside_airbnb.db (1)/inside_airbnb.db")
dbListTables(con)

# ----- Select listing and review table about amsterdam from the sqlite
listings_df <- dbGetQuery(con, "SELECT * FROM listing WHERE file_name = 'amsterdam_listings.csv.gz'")
reviews_df <- dbGetQuery(con, "SELECT * FROM review WHERE file_name = 'amsterdam_reviews.csv.gz'")

# ----- Get the tokens from the sqlite
tokens_all <- dbGetQuery(con, "select listing.listing_id,lemma from review_udipipe_info
           left join review on review_udipipe_info.doc_id = review.review_id
           left join listing on review.listing_id = listing.listing_id where review.file_name = 'amsterdam_reviews.csv.gz' ")
host_name_list <- dbGetQuery(con,"select host_id,host_name from host")

# ----- Rename the tokens
tokens_all <- tokens_all %>% rename(word = lemma) %>% group_by(word,listing_id)%>%count()
# ----- combine two tables
all_data_df <- listings_df %>% 
  left_join(reviews_df,by="listing_id")

# ----- get the new_description
new_description <- dbGetQuery(con, "select listing_id,new_description_cleaned from new_description_cleaned")
# ----- clean the environment
rm(reviews_df)
rm(listings_df)
dbDisconnect(con)
rm(con)
```

```{r}
library(qdap)
data("stop_words")
Fry_1000 <- as.data.frame(qdapDictionaries::Fry_1000)
colnames(Fry_1000) <- "word"

host_name <- as.data.frame(unique(tolower(host_name_list$host_name)))
colnames(host_name) <- "word"

neighbourhood_cleansed <- as.data.frame(unique(tolower(all_data_df$neighbourhood_cleansed)))
colnames(neighbourhood_cleansed) <- "word"

city_name <- as.data.frame(unique(tolower(all_data_df$city)))
colnames(city_name) <- "word"

 
customed_words <- 
  tibble(c("can","good","stay","airbnb","apartment","great","everything","really", "airbnb", "bnb", "room", "house", "place","nice","easy","really","everything","not","highly","with","to")) 
  
colnames(customed_words) <- "word"

# ----- Combine dictionaries into one
add_words <- 
  bind_rows(customed_words, city_name, neighbourhood_cleansed, host_name) %>%
  na.omit()

tokens_all <- tokens_all %>% anti_join(add_words)

all_data_df <- all_data_df %>%  left_join(host_name_list)

all_data_df <- all_data_df %>% left_join(unique(new_description))

# ----- to get the tokens_all_listings
library(tidytext)
tokens_all_listings <- all_data_df %>% select(listing_id,new_description_cleaned) %>% unique %>% unnest_tokens(word,new_description_cleaned) %>% anti_join(add_words) %>% group_by(listing_id,word)%>%count()

```

```{r}
# ----- Question a
#What are the dominant words per aggregation category (neighborhood, access to public transport etc.)?

# ----- Get the top 5 neighbourhood  
top_5 <- all_data_df %>% 
  select(listing_id,neighbourhood_cleansed) %>%
  unique(.) %>% 
  group_by(neighbourhood_cleansed) %>% 
  summarise(total =n()) %>% 
  arrange(desc(total)) %>% 
  top_n(5)

# 
avg_rating_neigh <- all_data_df %>% 
  select(listing_id,neighbourhood_cleansed,review_scores_rating) %>%
  unique(.) %>% 
  group_by(neighbourhood_cleansed) %>% 
  summarise(avg.rating=mean(review_scores_rating)) %>%
  filter(neighbourhood_cleansed %in% top_5$neighbourhood_cleansed)

 tokens_top_5 <- all_data_df %>% 
  select(listing_id,neighbourhood_cleansed) %>% 
  filter(neighbourhood_cleansed %in% top_5$neighbourhood_cleansed) %>% 
  unique(.)

# ----- Calculate the average rating for top5 neighbourhood
neighbourhood_tokens <- neighbourhood_tokens <- tokens_all %>% 
  right_join(tokens_top_5) %>%  group_by(neighbourhood_cleansed,word) %>% # word is better
  summarise(total=sum(n)) %>% 
  arrange(desc(total)) 

# Now loop through and get the top 10 tokens 
# per neighbourhood for the review 

for(neighb in 1:nrow(top_5)){
  print(paste0("For neighbourhood: ",top_5$neighbourhood_cleansed[neighb]))
  
  toprint <- neighbourhood_tokens %>% ungroup() %>% filter(neighbourhood_cleansed == top_5$neighbourhood_cleansed[neighb]) %>% top_n(30,total) %>% mutate(rank = row_number())
  print(toprint)
}

top10_word_neigh <- list()

library(wordcloud)
# -----word cloud
for(neighb in 1:nrow(top_5)){
  print(paste0("For neighbourhood: ",top_5$neighbourhood_cleansed[neighb]))
  
  toprint <- neighbourhood_tokens %>% ungroup() %>% filter(neighbourhood_cleansed == top_5$neighbourhood_cleansed[neighb]) %>% top_n(10,total) %>% mutate(rank = row_number())
  print(toprint)

 top10_word_neigh[[neighb]] <- toprint 
  
# ----- wordcloud
  wordcloud(words = toprint$word, freq = toprint$total, min.freq = 1, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, "Dark2"))
# ----- Bar plot
  top10bar <-toprint %>% ggplot(aes(x=fct_reorder(word,total),y=total)) + geom_bar(stat="identity",fill="lightblue")+coord_flip() +theme_bw() + 
    theme(panel.border = element_blank(),panel.grid.major = element_blank(), panel.grid.minor = element_blank(),axis.line = element_line(colour = "black"),axis.title.x=element_text(size=14,face="bold",hjust=0.5),axis.title.y =element_text(size=14,face="bold",hjust=0.5)) + labs(x="Total", y="Dominant Words", title = paste0("For neighbourhood: ",top_5$neighbourhood_cleansed[neighb])) 
  print(top10bar)
}

library(data.table)
top10_word_neigh <- rbindlist(top10_word_neigh) %>% arrange(rank,neighbourhood_cleansed)

top10_word_neigh <- top10_word_neigh %>% right_join(avg_rating_neigh)

top10_word_neigh$neighbourhood_cleansed <- as.factor(top10_word_neigh$neighbourhood_cleansed)

# ----- Create the rank chart
ggplot(data = top10_word_neigh, aes(x = fct_reorder(word,rank), y = rank, group =neighbourhood_cleansed )) +
  geom_line(aes(color = neighbourhood_cleansed, alpha = 1), size = 2) +
  geom_point(aes(color = neighbourhood_cleansed, alpha = 1), size = 4)+
  scale_y_reverse(breaks = 1:10) +
  labs(x = "Dominant Words",y = "Ranking",title = "Top10 Dominant Words Ranking Chart")+
  theme_set(theme_bw()) +
  theme(panel.grid.major = element_blank())

```

```{r}
# ----- Property 
# ----- Get the top 5 property_type
top_5 <- all_data_df %>% 
  select(listing_id,property_type) %>%
  unique(.) %>% 
  group_by(property_type) %>% 
  summarise(total =n()) %>% 
  arrange(desc(total)) %>% 
  top_n(5)

# -----
tokens_top_5 <- all_data_df %>% 
  select(listing_id,property_type) %>% 
  filter(property_type %in% top_5$property_type) %>% 
  unique(.)
# -----
property_tokens <- tokens_all %>% 
  right_join(tokens_top_5) %>%  group_by(property_type,word) %>% 
  summarise(total=sum(n)) %>% 
  arrange(desc(total)) 

# Now loop through and get the top 20 tokens 
# per neighbourhood for the review 
top10_word_property <- list()

for(i in 1:nrow(top_5)){
  print(paste0("For property_type: ",top_5$property_type[i]))
  
  toprint <- property_tokens %>% ungroup() %>% filter(property_type == top_5$property_type[i]) %>% top_n(10,total)  %>% mutate(rank = row_number())
  top10_word_property[[i]] <- toprint 
  print(toprint)
  
# ----- Wordcloud  
  wordcloud(words = toprint$word, freq = toprint$total, min.freq = 1, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, "Dark2"))
# ----- Bar plot
  top10bar <-toprint %>% ggplot(aes(x=fct_reorder(word,total),y=total)) + geom_bar(stat="identity",fill="lightblue")+coord_flip() +theme_bw() + 
    theme(panel.border = element_blank(),panel.grid.major = element_blank(), panel.grid.minor = element_blank(),axis.line = element_line(colour = "black"),axis.title.x=element_text(size=14,face="bold",hjust=0.5),axis.title.y =element_text(size=14,face="bold",hjust=0.5)) + labs(x="Total", y="Dominant Words", title = paste0("For Property Type: ",top_5$property_type[i]))
  print(top10bar)
}

top10_word_property <- rbindlist(top10_word_property)

ggplot(data = top10_word_property, aes(x = fct_reorder(word,rank), y = rank, group = property_type )) +
  geom_line(aes(color = property_type, alpha = 1), size = 2) +
  geom_point(aes(color = property_type, alpha = 1), size = 4)+
  scale_y_reverse(breaks = 1:10) +
  labs(x = "Dominant Words",y = "Ranking",title = "Top10 Dominant Words Ranking Chart")+
  theme_set(theme_bw()) +
  theme(panel.grid.major = element_blank())

```

```{r}
#----- Room type
room_type <- as.factor(unique(all_data_df$room_type))

room_type_tokens <- all_data_df %>% select(listing_id,room_type)%>% unique() %>%
  left_join(tokens_all) %>%  group_by(room_type,word) %>% 
  summarise(total=sum(n)) %>% 
  arrange(desc(total)) 

top10_word_roomtype <- list()

for(i in 1:length(room_type)){
  print(paste0("For room_type: ",room_type[i]))
  toprint <- room_type_tokens %>% ungroup() %>% filter(room_type == room_type[i]) %>% top_n(10,total) %>% mutate(rank = row_number())
  print(toprint)
  top10_word_roomtype[[i]] <- toprint
  
  # ----- Word Cloud
   wordcloud(words = toprint$word, freq = toprint$total, min.freq = 1, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, "Dark2"))
  # ----- Bar plot
  top10bar <-toprint %>% ggplot(aes(x=fct_reorder(word,total),y=total)) + geom_bar(stat="identity",fill="lightblue")+coord_flip() +theme_bw() + 
    theme(panel.border = element_blank(),panel.grid.major = element_blank(), panel.grid.minor = element_blank(),axis.line = element_line(colour = "black"),axis.title.x=element_text(size=14,face="bold",hjust=0.5),axis.title.y =element_text(size=14,face="bold",hjust=0.5))
  print(top10bar)
}

 top10_word_roomtype <- rbindlist(top10_word_roomtype)
 
 ggplot(data = top10_word_roomtype, aes(x = fct_reorder(word,rank), y = rank, group = room_type )) +
  geom_line(aes(color = room_type, alpha = 1), size = 2) +
  geom_point(aes(color = room_type, alpha = 1), size = 4)+
  scale_y_reverse(breaks = 1:10) +
  labs(x = "Dominant Words",y = "Ranking",title = "Top10 Dominant Words Ranking Chart")+
  theme_set(theme_bw()) +
  theme(panel.grid.major = element_blank())

```

```{r}
# ----- Question b
# What are the most common word combinations used to describe a property listing?

library(qdap)
# ----- Take the tokens and cast them 
# ----- to a dtm using the tm package 
dominantwords <- tokens_all %>% group_by(word)%>% summarise(n = sum(n)) %>% arrange(desc(n)) %>% head(10) %>% pull(word) %>% as.character()

# ----- create the dtm of reviews
library(tidytext)
listings_dtm <- tokens_all %>% 
  cast_dtm(listing_id,word,n)
dim(listings_dtm)

library(tm)
# ----- remove some sparse terms to reduce the dimension
listings_dtm <- removeSparseTerms(listings_dtm, 0.8)
dim(listings_dtm)
inspect(listings_dtm)

# ----- Get the correlation between terms
assocs_words <- findAssocs(listings_dtm,dominantwords,corlimit = 0.85)
assocs_words <- as.data.frame(unlist(assocs_words))
colnames(assocs_words)[1] <- "correlation"
assocs_words$combinations <- rownames(assocs_words)
library(ggraph)
library(igraph)
assocs_words %>%
  filter(correlation > .15) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
    geom_edge_link() +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void() + labs(title = "Word Combinations")
```

```{r readform}
# ----- Question C
# What variables can be extracted from the text that can be related with the rating score ?
# ----- Tf-idf 
tokens_all_tf_idf <- tokens_all %>% 
  bind_tf_idf(word,listing_id,n)

# ----- lets try to filter important words 
# ----- using the left and right trim 
hist(tokens_all_tf_idf$tf_idf,breaks = 200,main="TF-IDF plot")

tokens_all_tf_idf <- tokens_all_tf_idf %>% 
  filter(tf_idf<0.2)

hist(tokens_all_tf_idf$tf_idf,breaks = 200,main="TF-IDF plot")

# ----- Ok from the plot we see that the cut-off value is at 0.05
tokens_all_tf_idf <- tokens_all_tf_idf %>% 
  filter(tf_idf<0.05)

hist(tokens_all_tf_idf$tf_idf,breaks = 200,main="TF-IDF plot")

# ----- Lets now remove also very common terms 
# ----- Those with tf-idf <0.001 as shown in the chart below 

tokens_all_tf_idf <- tokens_all_tf_idf %>% 
  filter(tf_idf>0.001)

# ----- Calculate the average rating.
rating_categories <- all_data_df %>% 
  group_by(listing_id) %>% 
  summarise(avg_rating = mean(review_scores_rating)) %>%
  ungroup()

# ----- Lets find the levels that we want to aggregate the words 
quantile(rating_categories$avg_rating)

# ----- Now assign them in a rating group
rating_categories$rating_category <- ifelse(rating_categories$avg_rating<98,1,2)

# ----- extract the feature from reviews
ratings_categories_tokens <- tokens_all %>% left_join(rating_categories) %>% 
  group_by(rating_category,word) %>% summarise(total =sum(n))
  
ratings_categories_tokens %>% filter(rating_category==1) %>% arrange(desc(total)) %>% top_n(10)

ratings_categories_tokens %>% filter(rating_category==2) %>% arrange(desc(total)) %>% top_n(10)

# From the listings

# ----- Using the textfeatures package get the feature from the description
library(textfeatures)
feature_description <- all_data_df %>% 
  select(listing_id,new_description_cleaned,review_scores_rating) %>% 
  unique() %>% 
  rename(text = new_description_cleaned) %>%
  textfeatures(sentiment = FALSE,word_dims=0)
```

```{r message=FALSE, include=FALSE}
# ------ a. Is readability of the property description an important predictor of the satisfaction ratings?
all_listings <- all_data_df %>% select(listing_id,new_description,review_scores_rating) %>% unique()

library(tm)

# Create the dataframe for storing the readability.
readability_fle_all <- data.frame()
readability_ari_all <- data.frame()
readability_lin_all <- data.frame()
readability_for_all <- data.frame()

library(qdap)

# ----- Calculate the readability and fomality
for(i in 1:3000){
  readability_fle <- data.frame() 
  readability_ari <- data.frame()
  readability_lin <- data.frame()
  readability_for <- data.frame()
  readability_all <- data.frame()
  
  this_text <- iconv(all_listings$new_description[i])
  this_text <- removeNumbers(this_text)
  this_text <- removePunctuation(this_text)

  tryCatch(readability_fle <- flesch_kincaid(this_text),error=function(e){
    cat("Error parsing")
  })
  
  tryCatch(readability_ari <- automated_readability_index(this_text),error=function(e){
    cat("Error parsing")
  })
  
  tryCatch(readability_lin <- linsear_write(this_text),error=function(e){
    cat("Error parsing")
  })  
  
  tryCatch(readability_for <- formality(this_text),error=function(e){
    cat("Error parsing")
  })  
  
  if(!is.null(readability_fle$Readability)){
  
     readability_fle <- readability_fle$Readability
     readability_fle$listing_id <- all_listings$listing_id[i]
     readability_fle_all <- bind_rows(readability_fle_all,readability_fle) 
  }
  
  if(!is.null(readability_ari$Readability)){
  
     readability_ari <- readability_ari$Readability
     readability_ari$listing_id <- all_listings$listing_id[i]
     readability_ari_all <- bind_rows(readability_ari_all,readability_ari) 
  }
  if(!is.null(readability_lin$Readability)){
  
     readability_lin <- readability_lin$Readability
     readability_lin$listing_id <- all_listings$listing_id[i]
     readability_lin_all <- bind_rows(readability_lin_all,readability_lin) 
  }
  
  if(!is.null(readability_for$formality)){
  
     readability_for <- readability_for$formality
     readability_for$listing_id <- all_listings$listing_id[i]
     readability_for_all <- bind_rows(readability_for_all,readability_for) 
   }
 print(i)
}

# -----Clean the environment
rm(readability_fle)
rm(readability_ari)
rm(readability_lin)
rm(readability_for)
rm(listings_df)
# ----- Merge multiple tables 
readability_fle_all <- readability_fle_all %>% 
  select(listing_id,FK_grd.lvl,FK_read.ease ,syllable.count,word.count)

readability_ari_all <- readability_ari_all %>%
  select(listing_id,Automated_Readability_Index)

readability_lin_all <- readability_lin_all %>%
  select(listing_id,hard_easy_sum,sent.per.100,Linsear_Write)

readability_for_all <- readability_for_all %>% 
  select(listing_id,formality)

#-----merge multiple dataframe
readability_all <- Reduce(function(x, y) merge(x, y, all=TRUE), list(readability_ari_all,readability_lin_all,readability_fle_all,readability_for_all)) 
#-----clean the memory
rm(readability_ari_all)
rm(readability_for_all)
rm(readability_fle_all)
rm(readability_lin_all)
# ----- Replace the missing value with 0
readability_all[is.na(readability_all)] <- 0

# ----- Add rating in the df in order to run regression model
readability_rating <- all_data_df %>% 
  select(listing_id,review_scores_rating) %>% 
  unique() %>% 
  right_join(readability_all) %>%
  select(-listing_id)
```

```{r}
# ----- Build the lm model(using strpwise methond to select features)
model_readabiity <- lm(review_scores_rating~.,data = readability_rating)
summary(model_readabiity)
step(model_readabiity)

#readabilty is not a good predictor, R square is so slow.
```

```{r}
# ----- b. Is mentioning the name of the owner important?

# ----- Choose the column we need from the all_data_df
hostname_reviews_df <- all_data_df %>% select(listing_id,review_id,review_scores_rating,host_name,comments)

# ----- Because the comments 
# ----- Romve punctuation in the hostname
hostname_reviews_df$host_name <- gsub('[[:punct:]]+',' ', hostname_reviews_df$host_name)
# ----- Remove extra white space
hostname_reviews_df$host_name <- gsub("\\s+"," ",hostname_reviews_df$host_name)

# ----- For this we are going to add a new column
 hostname_reviews_df$host_name_mentioned <-NA
# fuzzy match is more suitable in the question 
 for(i in 1:nrow(all_data_df)){
   check_h <- as.numeric(agrepl(hostname_reviews_df$host_name[i],
                               hostname_reviews_df$comments[i],
                               ignore.case = T,max.distance = 0.1))
   hostname_reviews_df$host_name_mentioned[i] <- check_h
 }
 
# How does it look graphically 
ggplot(subset(hostname_reviews_df,!is.na(host_name_mentioned)),aes(x=factor(host_name_mentioned),y=review_scores_rating))+geom_boxplot()
# ----- run the T-test 
t.test(hostname_reviews_df$review_scores_rating~factor(hostname_reviews_df$host_name_mentioned))
```

```{r}
#-----Question D
#Using the textual description of the property supplied by the owner, how does this relate with the price that the property is listed for rent?

#----- get the price from the listings
all_listings <- all_data_df %>% select(listing_id,new_description,price) %>% 
  unique(.)
#-----Join the table to get the depedent variable
readability_price <- all_listings %>% 
  left_join(readability_all)

# ----- For working with the price we need to parse it first as a numeric 
readability_price$price <- as.numeric(gsub("\\$","",readability_price$price))

model1 <- lm(price~.,data=select(readability_price,-listing_id,-new_description))
summary(model1)


# ----- Using stepwise method to select significant variables
step(model1,steps = 10)
model2 <- model1 <- lm(price~Automated_Readability_Index+sent.per.100+ Linsear_Write + 
    FK_grd.lvl + syllable.count,data=select(readability_price,-listing_id,-new_description))
summary(model2)
```





